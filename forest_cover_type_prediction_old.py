# -*- coding: utf-8 -*-
"""Forest Cover Type Prediction old.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e0tZj7XfaRUurl8Gt7VVpHaEoSowM6On

# **Import The Libraries**
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import StandardScaler

"""# **Load The Dataset**"""

df = pd.read_csv('/content/drive/MyDrive/ML Datasets/Forest Cover Type Dataset.csv')

"""**Print Dataset Shape**"""

print("Dataset Shape:", df.shape)

"""**Print Dataset Description**"""

print("\nDescription: \n", df.describe())

"""**Print Dataset Information**"""

print("\nFirst 5 rows:\n", df.head())

"""**Print Group Wise Data**"""

print("\nGroup Wise Data:\n", df.groupby('Cover_Type').size())

"""# **Features and Target**"""

X = df.drop(['Cover_Type', 'Id'], axis=1) # Drop 'Id' as well
y = df['Cover_Type']  # Target variable (1â€“7)

"""# **Train-Test Split**"""

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

"""# **Feature Scaling**"""

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""# **Model Training**"""

model = RandomForestClassifier(
    n_estimators=200,
    random_state=42,
    n_jobs=-1
)
model.fit(X_train_scaled, y_train)

"""# **Predictions**"""

y_pred = model.predict(X_test_scaled)

"""# **Evaluation**"""

print("\nModel Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred, digits=3)
)

"""# **Predict on New Sample**"""

sample_data = pd.DataFrame([[                                         # Example new patch of land (replace values with actual data)
    300, 405, 150, 500, -550, 200, 100, 220, 250, 220,                # Numerical features
    1, 1, 0, 1,                                                       # Wilderness area (binary)
    *([0]*39), 1                                                      # Soil type (binary: last one = 1)
]], columns=X.columns)                                                # Add column names

sample_scaled = scaler.transform(sample_data)                         # Scale the input
predicted_class = model.predict(sample_scaled)[0]                     # Predict using trained model

cover_type_mapping = {
    1: "Spruce/Fir",
    2: "Lodgepole Pine",
    3: "Ponderosa Pine",
    4: "Cottonwood/Willow",
    5: "Aspen",
    6: "Douglas-fir",
    7: "Krummholz"  }                                                  # Map numeric prediction to category

sample_df = pd.DataFrame(sample_data, columns=X.columns)               # Create a DataFrame from sample_data and add the predicted class
sample_df['Predicted Type'] = cover_type_mapping[predicted_class]      # Add prediction to DataFrame
print("\nForest Cover Type Data with Prediction:")                     # Display full forest cover type data with prediction
print(sample_df.to_string(index=False))

print("\nPredicted Cover Type: ", cover_type_mapping[predicted_class])