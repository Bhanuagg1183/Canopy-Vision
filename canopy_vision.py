# -*- coding: utf-8 -*-
"""Canopy Vision.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eco49Ec3gwUwHItfChqA3Y4m_DXSIVas

# **CANOPY VISION**

# **Installing Python Libraries**

# **Importing Python libraries for data manipulation, visualization, and machine learning**

**Model Selection:** for splitting the data into training and testing sets.

**Standard Scaler:** to scale the features of the dataset.

**Random Forest Classifier:** is imported to implement different machine learning models.

**Metrics**: for evaluating the performance of the models using classification reports, confusion matrices, and accuracy scores.
"""

import numpy as np
import pandas as pd
from pandas.plotting import scatter_matrix
import matplotlib.pyplot as plt
from matplotlib import pyplot
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.preprocessing import StandardScaler

"""# **Loading The Dataset**
#Loading a CSV file into a pandas DataFrame
"""

df = pd.read_csv('/content/drive/MyDrive/ML Datasets/Forest Cover Type Dataset.csv')

"""#Displaying the shape of the Data"""

print("Dataset Shape: ", df.shape)

"""# Calculating and Displaying descriptive statistics for each numerical column in the Data

**count:** The number of non-null values in each column.

**mean:** The average value.

**std:** The standard deviation, which measures the spread of the data.

**min:** The minimum value.

**25%, 50%, 75%:** The quartiles, representing the 25th, 50th (median), and 75th percentiles.

**max:** The maximum value.

This helps in understanding the range, variability, and potential outliers in each feature.


"""

display(df.describe())

"""# Displaying the first 10 rows of the Data"""

display(df.head(10))

"""# Display Group-wise Data"""

display(df.groupby('Cover_Type').size())

"""# Adding a new feature of Euclidean Distance To Hydrology"""

df['Euclidean_Distance_To_Hydrology'] = (df['Horizontal_Distance_To_Hydrology']**2 + df['Vertical_Distance_To_Hydrology']**2)**0.5
display(df.head())

"""# Plotting Histograms for the first four features of the Dataset"""

pyplot.figure(figsize=(20, 20))
df.iloc[:, :4].hist()
pyplot.title('Forest Cover Type Dataset')
pyplot.show()

"""# Plotting Scatter Matrix for the first nine features of the Dataset"""

scatter_matrix(df.iloc[:, :9], alpha=0.5, figsize=(15, 15), diagonal='kde')
pyplot.title('Forest Cover Type Dataset')
pyplot.show()

"""# **Training the Model**

# Importing Classification Models:

**Linear Discriminant Analysis:** A linear model for classification and dimensionality reduction.

**Logistic Regression:** A linear model used for binary classification, but can be extended for multi-class classification.

**Decision Tree Classifier:** A tree-based model that makes decisions based on features.

**KNeighbors Classifier:** A non-parametric model that classifies data points based on the majority class of their nearest neighbors.

**Gaussian NB:** A naive Bayes classifier that assumes features follow a Gaussian distribution.

**SVC:** A Support Vector Machine model for classification.

**Random Forest Classifier:** An ensemble method that builds multiple decision trees and combines their predictions.
"""

#!pip install scikit-learn
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier

"""# Importing the Metrics"""

from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import StratifiedKFold
array = df.values

"""# Splitting and scaling the data"""

# Here the data will be split into input features and output features.
# Here we drop cover type from X as X represents input factors.
# Similarly we define Y as cover type as Y represents the output features.
x = df.drop(['Id', 'Cover_Type'], axis=1)
y = df['Cover_Type']

"""# Splitting the dataset into training and testing sets"""

# Here we have used random state = 1 to reproduce the same results everytime we run the project.
Xtrain, Xvalid, Ytrain, Yvalid = train_test_split(x, y, test_size=0.20, random_state=1)

"""# Creating and appending the list of models"""

models = []
models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))
models.append(('LDA', LinearDiscriminantAnalysis()))
models.append(('KNN', KNeighborsClassifier()))
models.append(('CART', DecisionTreeClassifier()))
models.append(('NB', GaussianNB()))
models.append(('SVM', SVC(gamma='auto')))
models.append(('RFC', RandomForestClassifier()))

"""# Creating and appending the lists of accuracy score"""

# Here we created three lists of names, cross validation results and cross validation mean scores which will be appended as we fit each of the models.
results = []
names = []
res = []

for name, model in models:
  k_fold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)
  cvresults = cross_val_score(model, Xtrain, Ytrain, cv=k_fold, scoring='accuracy')
  results.append(cvresults)
  names.append(name)
  res.append(cvresults.mean())
  print('%s: %f (%f)' %(name, cvresults.mean(),cvresults.std()))

"""# Plotting a Bar Graph comparing accuracy of various algorithms"""

# Here we compare the accuracy of the models by plotting their accuracy on a single bar graph to get the best results.
pyplot.ylim(0.1,0.9)
pyplot.bar(names, res, color=['violet', 'indigo', 'blue', 'green', 'yellow', 'orange', 'red'], width = 0.75)
pyplot.ylabel('Accuracy of The Models')
pyplot.xlabel('Name of Models')
pyplot.title("Algorithm Comparison")
pyplot.show()

"""# Initializing a Standard Scaler object"""

# Here, we have scaled the input features according to their contribution to the fianl output.
scaler = StandardScaler()
Xtrain_scaled = scaler.fit_transform(Xtrain)
Xtest_scaled = scaler.transform(Xvalid)

"""# Fitting the most Accurate Model i.e. Random Forest Classifier Model"""

model = RandomForestClassifier()
model.fit(Xtrain_scaled, Ytrain)
y_pre = model.predict(Xtest_scaled)

"""# Displaying Classification Report for all the seven models"""

from sklearn.metrics import classification_report
for name, model in models:
    print(f"Classification Report for {name}:\n{classification_report(Yvalid, y_pre, digits=4)}\n")

"""# Displaying Confusion Matrices for all the seven models"""

for name, model in models:
  cm = confusion_matrix(Yvalid, y_pre)
  plt.figure(figsize=(4, 4))
  sns.heatmap(cm, annot=True, fmt='d', cmap='Reds')
  # Here fmt = 'd' helps to convert the output data to integers.

  plt.title(f'Confusion Matrix for {name}')
  plt.xlabel('Predicted')
  plt.ylabel('Actual')
  plt.show()

"""# Displaying Accuracy Report for Random Forest Classifier Model"""

print("\nModel Accuracy: ", accuracy_score(Yvalid, y_pre))
labels = [1, 2, 3, 4, 5, 6, 7,]
print("\nClassification Report of Random Forest Classifier: \n", classification_report(Yvalid, y_pre, digits=4))

"""# Displaying Confusion Matrix for Random Forest Classifier Model"""

  cm = confusion_matrix(Yvalid, y_pre)
  plt.figure(figsize=(12, 8))
  sns.heatmap(cm, annot=True, fmt='d', cmap='Greens')
  # Here fmt = 'd' helps to convert the output data to integers.

  plt.title(f'Confusion Matrix for {name}')
  plt.xlabel('Predicted')
  plt.ylabel('Actual')
  plt.show()

"""# Displaying the accuracy through Bar Plot"""

accuracy = accuracy_score(Yvalid, y_pre)
plt.figure(figsize=(6, 6))
plt.bar(['Forest Cover Type Model'], [accuracy], color='olive')
plt.ylabel('Accuracy')
plt.title('Forest Cover Type Model Accuracy')
plt.ylim(0,1)
plt.show()

"""# Calculating and visualizing the feature importances from the trained Random Forest Classifier model"""

# Here we have plotted a bar graph comparing the contribution of different features towards the final output.
importances = model.feature_importances_
# Here coef refers to magnitude of coefficient which represents the importance of each feature in a linear model.

features = x.columns
indices = np.argsort(importances)[::-1]
# Here we sort the features importance in the descending order and return the indices.

plt.figure(figsize=(10, 6))
plt.title("Feature Importances - Random Forest")
plt.bar(range(x.shape[1]), importances[indices])
plt.xticks(range(x.shape[1]), features[indices], rotation=90)
# Here we rotate the labels by 90 degrees to make them readable.

plt.xlabel("Features")
plt.ylabel("Importance")
plt.tight_layout()
# Here we adjust the plot parameters automatically.

plt.show()

"""# **Predicting on New Data**"""

sample_data = pd.DataFrame([[
    2278, 341, 9, 0, 0, 1537, 201, 226, 165, 677,
    0, 0, 0, 1,
    *([0]*39), 1, 0
]], columns=x.columns)
# Here we enter the new forest cover sample data.

sample_scaled = scaler.transform(sample_data)
# Here we scale the input data as model was trained on scaled data.

predicted_class = model.predict(sample_scaled)[0]
# Here the model is trained to make the prediction.

cover_type_mapping = {1: "Spruce/Fir", 2: "Lodgepole Pine", 3: "Ponderosa Pine", 4: "Cottonwood/Willow", 5: "Aspen", 6: "Douglas-fir", 7: "Krummholz"}
# Here we map the output to the human readable string.

predicted_label = cover_type_mapping.get(predicted_class, "Unknown")
# Here we label the class as unknown if any of the forest cover types is not matched with the entered data.

sample_df = pd.DataFrame(sample_data, columns=x.columns)
sample_df['Predicted Type'] = predicted_label

print("\nForest Cover Type Data with Prediction: \n")
display(sample_data)
print("\nPredicted Cover Type: ", predicted_label)
